{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio\n",
      "MoviePy - Writing audio in test_videos/audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted\n",
      "Transcribing video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription complete\n",
      "Creating video\n",
      "Extracting frames\n",
      "Frames extracted\n",
      "Video saved at: test_videos/output.mp4\n",
      "Moviepy - Building video test_videos/output.mp4.\n",
      "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video test_videos/output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos/output.mp4\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import cv2\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, VideoFileClip\n",
    "from tqdm import tqdm\n",
    "\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.8\n",
    "FONT_THICKNESS = 2\n",
    "\n",
    "class VideoTranscriber:\n",
    "    def __init__(self, model_path, video_path):\n",
    "        self.model = whisper.load_model(model_path)\n",
    "        self.video_path = video_path\n",
    "        self.audio_path = ''\n",
    "        self.text_array = []\n",
    "        self.fps = 0\n",
    "        self.char_width = 0\n",
    "\n",
    "    def transcribe_video(self):\n",
    "        print('Transcribing video')\n",
    "        result = self.model.transcribe(self.audio_path)\n",
    "        text = result[\"segments\"][0][\"text\"]\n",
    "        textsize = cv2.getTextSize(text, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        asp = 16/9\n",
    "        ret, frame = cap.read()\n",
    "        width = frame[:, int(int(width - 1 / asp * height) / 2):width - int((width - 1 / asp * height) / 2)].shape[1]\n",
    "        width = width - (width * 0.1)\n",
    "        self.fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.char_width = int(textsize[0] / len(text))\n",
    "        \n",
    "        for j in tqdm(result[\"segments\"]):\n",
    "            lines = []\n",
    "            text = j[\"text\"]\n",
    "            end = j[\"end\"]\n",
    "            start = j[\"start\"]\n",
    "            total_frames = int((end - start) * self.fps)\n",
    "            start = start * self.fps\n",
    "            total_chars = len(text)\n",
    "            words = text.split(\" \")\n",
    "            i = 0\n",
    "            \n",
    "            while i < len(words):\n",
    "                words[i] = words[i].strip()\n",
    "                if words[i] == \"\":\n",
    "                    i += 1\n",
    "                    continue\n",
    "                length_in_pixels = (len(words[i]) + 1) * self.char_width\n",
    "                remaining_pixels = width - length_in_pixels\n",
    "                line = words[i] \n",
    "                \n",
    "                while remaining_pixels > 0:\n",
    "                    i += 1 \n",
    "                    if i >= len(words):\n",
    "                        break\n",
    "                    length_in_pixels = (len(words[i]) + 1) * self.char_width\n",
    "                    remaining_pixels -= length_in_pixels\n",
    "                    if remaining_pixels < 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        line += \" \" + words[i]\n",
    "                \n",
    "                line_array = [line, int(start) + 15, int(len(line) / total_chars * total_frames) + int(start) + 15]\n",
    "                start = int(len(line) / total_chars * total_frames) + int(start)\n",
    "                lines.append(line_array)\n",
    "                self.text_array.append(line_array)\n",
    "        \n",
    "        cap.release()\n",
    "        print('Transcription complete')\n",
    "    \n",
    "    def extract_audio(self, output_audio_path):\n",
    "        print('Extracting audio')\n",
    "        video = VideoFileClip(self.video_path)\n",
    "        audio = video.audio \n",
    "        audio.write_audiofile(output_audio_path)\n",
    "        self.audio_path = output_audio_path\n",
    "        print('Audio extracted')\n",
    "    \n",
    "    def extract_frames(self, output_folder):\n",
    "        print('Extracting frames')\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        asp = width / height\n",
    "        N_frames = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame = frame[:, int(int(width - 1 / asp * height) / 2):width - int((width - 1 / asp * height) / 2)]\n",
    "            \n",
    "            for i in self.text_array:\n",
    "                if N_frames >= i[1] and N_frames <= i[2]:\n",
    "                    text = i[0]\n",
    "                    text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "                    text_x = int((frame.shape[1] - text_size[0]) / 2)\n",
    "                    text_y = int(height/2)\n",
    "                    cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "                    break\n",
    "            \n",
    "            cv2.imwrite(os.path.join(output_folder, str(N_frames) + \".jpg\"), frame)\n",
    "            N_frames += 1\n",
    "        \n",
    "        cap.release()\n",
    "        print('Frames extracted')\n",
    "\n",
    "    def create_video(self, output_video_path):\n",
    "        print('Creating video')\n",
    "        image_folder = os.path.join(os.path.dirname(self.video_path), \"frames\")\n",
    "        if not os.path.exists(image_folder):\n",
    "            os.makedirs(image_folder)\n",
    "        \n",
    "        self.extract_frames(image_folder)\n",
    "        \n",
    "        print(\"Video saved at:\", output_video_path)\n",
    "        images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "        images.sort(key=lambda x: int(x.split(\".\")[0]))\n",
    "        \n",
    "        frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "        \n",
    "        clip = ImageSequenceClip([os.path.join(image_folder, image) for image in images], fps=self.fps)\n",
    "        audio = AudioFileClip(self.audio_path)\n",
    "        clip = clip.set_audio(audio)\n",
    "        clip.write_videofile(output_video_path)\n",
    "\n",
    "# Example usage\n",
    "model_path = \"base\"\n",
    "video_path = \"./demo.mp4\"\n",
    "output_video_path = \"test_videos/output.mp4\"\n",
    "output_audio_path = \"test_videos/audio.mp3\"\n",
    "\n",
    "transcriber = VideoTranscriber(model_path, video_path)\n",
    "transcriber.extract_audio(output_audio_path=output_audio_path)\n",
    "transcriber.transcribe_video()\n",
    "transcriber.create_video(output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deleteing the frames\n",
    "\n",
    "folder_path = 'frames'  # Path to the folder containing the files\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Iterate over each file and delete if it has a \".jpg\" extension\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    if os.path.isfile(file_path) and file.endswith('.jpg'):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted file: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Skipping {file_path}, it is not a .jpg file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
